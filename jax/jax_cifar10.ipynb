{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-G7aU1jYcw4"
      },
      "source": [
        "This notebook can be used in Google Colab\n",
        "\n",
        "It implements a CIFAR10 training using JAX Deep Learning framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AEUhvygLYhoI"
      },
      "outputs": [],
      "source": [
        "# This notebook is inspired from JAX mnist example\n",
        "# https://jax.readthedocs.io/en/latest/notebooks/neural_network_with_tfds_data.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DhOfE5WXp2aq"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Ensure TF does not see GPU and grab all GPU memory.\n",
        "tf.config.set_visible_devices([], device_type=\"GPU\")\n",
        "\n",
        "\n",
        "def get_data_from_tfds(\n",
        "    name: str,\n",
        "    data_dir: Path,\n",
        ") -> Tuple[tf.Tensor | tf.data.Dataset, tf.Tensor | tf.data.Dataset]:\n",
        "    \"\"\"Fetch full datasets for evaluation.\n",
        "\n",
        "    Args:\n",
        "        name: name of the dataset for tfds.load() method\n",
        "        data_dir: path to save the data\n",
        "    Returns:\n",
        "        tfds.load returns tf.Tensors (or tf.data.Datasets if batch_size != -1)\n",
        "    \"\"\"\n",
        "    cifar10_data, _ = tfds.load(\n",
        "        name=name,\n",
        "        batch_size=-1,\n",
        "        data_dir=data_dir,\n",
        "        with_info=True,\n",
        "    )\n",
        "    cifar10_data = tfds.as_numpy(cifar10_data)\n",
        "    train_data, test_data = cifar10_data[\"train\"], cifar10_data[\"test\"]\n",
        "    return train_data, test_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tJF-qlv-oK7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed86b214-aa47-4eed-b0eb-66fcc481e1a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "import jax.numpy as jnp\n",
        "from jax.example_libraries import stax, optimizers\n",
        "\n",
        "train_data, test_data = get_data_from_tfds(name=\"cifar10\", data_dir=Path('/tmp/tfds'))\n",
        "\n",
        "X_train, Y_train = train_data['image'], train_data['label']\n",
        "X_test, Y_test = test_data['image'], test_data['label']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = jnp.array(X_train, dtype=jnp.float32),\\\n",
        "                                   jnp.array(X_test, dtype=jnp.float32),\\\n",
        "                                   jnp.array(Y_train, dtype=jnp.float32),\\\n",
        "                                   jnp.array(Y_test, dtype=jnp.float32)\n",
        "classes =  jnp.unique(Y_train)\n",
        "conv_init, conv_apply = stax.serial(\n",
        "    stax.Conv(32, (3,3), padding=\"SAME\"),\n",
        "    stax.Relu,\n",
        "    stax.MaxPool(window_shape=(2, 2), strides=(2, 2)),\n",
        "    stax.Conv(16, (3,3), padding=\"SAME\"),\n",
        "    stax.Relu,\n",
        "    stax.MaxPool(window_shape=(2, 2), strides=(2, 2)),\n",
        "    stax.Flatten,\n",
        "    stax.Dense(64),\n",
        "    stax.Relu,\n",
        "    stax.Dense(len(classes)),\n",
        "    stax.Softmax\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9rcRN6DnbSL",
        "outputId": "76d69f0c-bbac-4650-c65f-c415614dd6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights : (3, 3, 3, 32), Biases : (1, 1, 1, 32)\n",
            "Weights : (3, 3, 32, 16), Biases : (1, 1, 1, 16)\n",
            "Weights : (1024, 64), Biases : (64,)\n",
            "Weights : (64, 10), Biases : (10,)\n"
          ]
        }
      ],
      "source": [
        "# Init weights and verify the shapes\n",
        "import jax\n",
        "rng = jax.random.PRNGKey(123)\n",
        "\n",
        "weights = conv_init(rng, (18,32,32,3))[1]\n",
        "\n",
        "for w in weights:\n",
        "    if w:\n",
        "        w, b = w\n",
        "        print(\"Weights : {}, Biases : {}\".format(w.shape, b.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-Y_nQlIncX6",
        "outputId": "3e4c6d0e-2c4a-4ec3-f3f9-4797f7da7865"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Make a prediction and verify output shape\n",
        "preds = conv_apply(weights, X_train[:5])\n",
        "preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-DHbTGDxqkWW"
      },
      "outputs": [],
      "source": [
        "from typing import Callable\n",
        "\n",
        "def CrossEntropyLoss(\n",
        "    weights: list,\n",
        "    input_data: jax.Array,\n",
        "    targets: jax.Array,\n",
        ") -> jax.Array:\n",
        "    \"\"\"Implement of cross entropy loss.\n",
        "\n",
        "    Args:\n",
        "        weights: list from _, _, opt_get_weights = optimizers.adam(lr), opt_get_weights(opt_state)\n",
        "        input_data: data to predict\n",
        "        targets: groundtruth targets in one hot encoding\n",
        "\n",
        "    Returns:\n",
        "        loss value\n",
        "    \"\"\"\n",
        "    preds = conv_apply(weights, input_data)\n",
        "    log_preds = jnp.log(preds + tf.keras.backend.epsilon())\n",
        "    return -jnp.mean(targets * log_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-lXqj9Qnq9Gp"
      },
      "outputs": [],
      "source": [
        "from jax import value_and_grad\n",
        "from tqdm import tqdm\n",
        "\n",
        "def TrainModelInBatches(\n",
        "    X: jax.Array,\n",
        "    Y: jax.Array,\n",
        "    epochs: int,\n",
        "    opt_state: jax.example_libraries.optimizers.OptimizerState,\n",
        "    opt_update: Callable,\n",
        "    opt_get_weights: Callable,\n",
        "    batch_size: int,\n",
        ") -> jax.example_libraries.optimizers.OptimizerState:\n",
        "    \"\"\"Train Jax model in batches.\n",
        "\n",
        "    Args:\n",
        "        X: training input\n",
        "        Y: groundtruth in one hot encoding\n",
        "        epochs: number of epochs\n",
        "        opt_state: from opt_init(weights)\n",
        "        opt_update: from _, opt_update, _ = optimizers.adam(lr)\n",
        "        opt_get_weights: from _, _, opt_get_weights = optimizers.adam(lr)\n",
        "        batch_size: batch size for training\n",
        "\n",
        "    Returns:\n",
        "        updated opt_state\n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(epochs):\n",
        "        batches = jnp.arange((X.shape[0] // batch_size) + 1)\n",
        "        progress_bar = tqdm(batches, position=0, leave=True)\n",
        "\n",
        "        losses = []\n",
        "        for batch in batches:\n",
        "            if batch != batches[-1]:\n",
        "                start, end = int(batch * batch_size), int(batch * batch_size + batch_size)\n",
        "            else:\n",
        "                start, end = int(batch * batch_size), None\n",
        "\n",
        "            X_batch, Y_batch = X[start:end], Y[start:end]\n",
        "\n",
        "            loss, gradients = value_and_grad(CrossEntropyLoss)(\n",
        "                opt_get_weights(opt_state),\n",
        "                X_batch,\n",
        "                Y_batch,\n",
        "            )\n",
        "\n",
        "            ## Update Weights\n",
        "            opt_state = opt_update(i, gradients, opt_state)\n",
        "\n",
        "            losses.append(loss)\n",
        "\n",
        "            progress_bar.set_description(f\"Epoch {i+1}/{epochs}\")\n",
        "            progress_bar.set_postfix(train_loss=jnp.round(jnp.array(losses).mean(), decimals=3))\n",
        "            progress_bar.update()\n",
        "\n",
        "    return opt_state"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = jax.random.PRNGKey(42)\n",
        "learning_rate = jnp.array(0.0001)\n",
        "epochs = 2\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "opt_init, opt_update, opt_get_weights = optimizers.adam(learning_rate)\n",
        "opt_state = opt_init(weights)\n",
        "one_hot_targets = jax.nn.one_hot(Y_train, num_classes=len(classes))\n",
        "\n",
        "\n",
        "final_opt_state = TrainModelInBatches(\n",
        "    X=X_train,\n",
        "    Y=one_hot_targets,\n",
        "    epochs=epochs,\n",
        "    opt_state=opt_state,\n",
        "    opt_update=opt_update,\n",
        "    opt_get_weights=opt_get_weights,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bAlHHEoxdxf",
        "outputId": "2827322a-8182-4dab-e7bb-fca1c09356a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 391/391 [03:53<00:00,  1.68it/s, train_loss=0.763]\n",
            "Epoch 2/2: 100%|██████████| 391/391 [03:27<00:00,  1.88it/s, train_loss=0.24200001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MakePredictions(\n",
        "    weights: list[Tuple[jax.Array, jax.Array]],\n",
        "    input_data: jax.Array,\n",
        "    batch_size: int,\n",
        ") -> list[jax.Array]:\n",
        "    \"\"\"Make predictions for a batch of data.\n",
        "\n",
        "    Args:\n",
        "        weights: list from _, _, opt_get_weights = optimizers.adam(lr), opt_get_weights(opt_state)\n",
        "        input_data: input data of shape (batch_size, width, height, channels)\n",
        "        batch_size (int): The batch size.\n",
        "    Returns:\n",
        "        A list of predictions.\n",
        "    \"\"\"\n",
        "    batches = jnp.arange((input_data.shape[0] // batch_size) + 1)  ### Batch Indices\n",
        "\n",
        "    preds = []\n",
        "    for batch in tqdm(batches, position=0, leave=True):\n",
        "        if batch != batches[-1]:\n",
        "            start, end = int(batch * batch_size), int(batch * batch_size + batch_size)\n",
        "        else:\n",
        "            start, end = int(batch * batch_size), None\n",
        "\n",
        "        X_batch = input_data[start:end]\n",
        "\n",
        "        if X_batch.shape[0] != 0:\n",
        "            preds.append(conv_apply(weights, X_batch))\n",
        "\n",
        "    return preds\n"
      ],
      "metadata": {
        "id": "xx5KyUmGydNE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = MakePredictions(opt_get_weights(final_opt_state), X_test, batch_size=batch_size)\n",
        "\n",
        "## Combine predictions of all batches\n",
        "test_preds = jnp.concatenate(test_preds).squeeze()\n",
        "\n",
        "test_preds = jnp.argmax(test_preds, axis=1)\n",
        "\n",
        "train_preds = MakePredictions(opt_get_weights(final_opt_state), X_train, batch_size=batch_size)\n",
        "\n",
        "train_preds = jnp.concatenate(train_preds).squeeze()\n",
        "\n",
        "train_preds = jnp.argmax(train_preds, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6pYkbalDG_7",
        "outputId": "e0d9f08d-504a-46c9-daaa-7fa6547a582a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:13<00:00,  5.91it/s]\n",
            "100%|██████████| 391/391 [01:09<00:00,  5.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Train Accuracy : {:.3f}\".format(accuracy_score(Y_train, train_preds)))\n",
        "print(\"Test  Accuracy : {:.3f}\".format(accuracy_score(Y_test, test_preds)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsBVtxehDUHx",
        "outputId": "aac3c278-bd81-400b-8402-696b54fb84df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy : 0.193\n",
            "Test  Accuracy : 0.192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gbSnqwR-DY6b"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}